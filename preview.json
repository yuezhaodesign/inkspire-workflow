[
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #1: Defining Code Style Guides\n**Content Type:** Conceptual\n**Cognitive Focus:** Activation, conceptual understanding\n\n**Scaffold Prompt:**\nBefore reading further, take a moment to think about what a “code style guide” is. Have you encountered one before, perhaps implicitly in a course or project? In your own words, what purpose do you think these guides serve in a team or open-source project?\n\n**Strategy Foundation:** Activation Prompts, Explanation Generation\n**Expected Engagement Time:** 2-5 minutes\n**Collaboration Mode:** Individual\n\n**Learning Objective:** Students will activate prior knowledge about code style and understand the fundamental purpose of style guides in software development.\n\n**Instructor Note:** Encourage students to share their initial thoughts. This helps surface existing mental models and sets the stage for understanding why formal style guides are important in professional contexts. You might ask for examples of style choices they've made (e.g., variable naming, indentation).",
    "_anchor_text": "Many companies, projects, and even programming languages formally de ne them in the form of “style guides” [ 1 – 4 ] that commonly cover the following aspects:",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #2: The Limits of Automation\n**Content Type:** Conceptual\n**Cognitive Focus:** Critical thinking, understanding nuances, real-world application\n\n**Scaffold Prompt:**\nThis section highlights that not all code style guidelines can be automatically checked. Why do you think rules like \"clarity and specificity of code comments\" are so difficult for a machine to evaluate? Can you think of another example of a coding best practice that would require human judgment rather than a simple automated check?\n\n**Strategy Foundation:** Explanation Generation, Discussion Prompt\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Pair\n\n**Learning Objective:** Students will critically analyze the limitations of automated code analysis and appreciate the role of human judgment in maintaining code quality.\n\n**Instructor Note:** Guide students to consider the difference between syntactic rules (easy to automate) and semantic or pragmatic rules (harder to automate). Encourage them to think about the 'meaning' or 'intent' behind code, which is often what human judgment assesses.",
    "_anchor_text": "However, nuanced guidelines or those with exceptions are di cult to automatically verify in their entirety (e.g., naming conventions and justi ed deviations in legacy code), and some guidelines cannot be captured by precise rules at all (e.g., clarity and speci city of code comments) and rely on human judgement and collective developer knowledge.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #3: The Role of Readability Mentors\n**Content Type:** Conceptual\n**Cognitive Focus:** Role understanding, connecting roles to practices\n\n**Scaffold Prompt:**\nImagine you are an inexperienced developer. How might a \"readability mentor\" be more helpful than an automated linter when trying to improve your code? What unique value does their human guidance, including summarizing best practices and providing references, offer?\n\n**Strategy Foundation:** Explanation Generation, Analogy Construction (implicit comparison to linters)\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Small Group\n\n**Learning Objective:** Students will understand the distinct role and value of human mentorship in code quality, differentiating it from automated tools.\n\n**Instructor Note:** Facilitate a discussion comparing the 'why' behind a mentor's feedback versus a linter's 'what'. Mentors can provide context, explain trade-offs, and offer personalized learning, which linters cannot.",
    "_anchor_text": "Dedicated style experts in a given language, called “readability mentors”, guide inexperienced developers towards pro ciency in the language [ 23 ]. Readability mentors commonly summarize a best practice in a few sentences and at the end of the comment include a URL for the change author as a reference. Figure 1 shows an example of a comment posted by a readability mentor.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #4: Deconstructing Model Input/Output\n**Content Type:** Hybrid\n**Cognitive Focus:** System understanding, input/output mapping, translation\n\n**Scaffold Prompt:**\nThis paragraph describes the model's input and target. If you were to provide an example, what would a 'task prompt' look like for a Python function that calculates a factorial? And what would a 'target' look like if that function had a best practice violation (e.g., an unclear variable name)? Try to mentally map these abstract descriptions to concrete examples.\n\n**Strategy Foundation:** Code-Concept Mapping, Translation Exercises (mental)\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Individual\n\n**Learning Objective:** Students will translate abstract descriptions of a machine learning model's input and output into concrete, imagined examples, enhancing their understanding of the system's mechanics.\n\n**Instructor Note:** Encourage students to be specific. For instance, a task prompt might be `\"# Refactor this function for clarity\"` and a target could be `\"line 5, variable 'a' -> https://example.com/naming-conventions\"`. This helps bridge the gap between conceptual understanding and practical application.",
    "_anchor_text": "For the best practice analysis, the input to the model is a task\\nprompt and source code, and the target is a source code location and\\na URL for a best practice violation. The task prompt is formatted as a\\nxed-text code comment, using the programming language’s appropriate commenting style. It describes the task in natural language\\nand precedes the source code, which is a direct textual representation of one  le.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #5: Pipeline Design Rationale\n**Content Type:** Hybrid\n**Cognitive Focus:** System architecture understanding, reasoning about design decisions\n\n**Scaffold Prompt:**\nThe authors explain *why* they split dataset creation into two steps. What does it mean for the output of the preprocessing step to be \"agnostic to the model’s input/target representation\"? How does this 'agnostic' quality contribute to \"improving feature velocity\" and allowing \"quick iterations\"?\n\n**Strategy Foundation:** Explanation Generation, Purpose Articulation\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Pair\n\n**Learning Objective:** Students will analyze and articulate the design rationale behind a multi-stage data pipeline, understanding concepts like modularity and its impact on development efficiency.\n\n**Instructor Note:** Guide students to think about how decoupling stages allows changes in one part (e.g., how the model sees data) without requiring a complete re-run of an expensive prior step. This is a common software engineering principle.",
    "_anchor_text": "Figure 2 shows the architecture of the model-training pipeline, which consists of three parts. We split dataset creation into two steps (preprocessing and curation) because the  rst step is signi -\\ncantly more expensive as it operates on a much larger amount of\\ndata. The output of the preprocessing step is agnostic to the model’s\\ninput/target representation. This separation improves feature velocity by enabling quick iterations on example representations and\\nother example-level adjustments.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #6: Evaluating Evaluation Limitations\n**Content Type:** Conceptual/Problem-Solving\n**Cognitive Focus:** Critical evaluation, understanding research limitations, error prediction\n\n**Scaffold Prompt:**\nThis paragraph identifies a key limitation of the evaluation: human comments are correct but not exhaustive. How might this limitation impact the *training* of the AI model? What kind of 'mistakes' might the model make, or what opportunities might it miss, because its training data isn't exhaustive?\n\n**Strategy Foundation:** Metacognitive Prompts, Error Prediction\n**Expected Engagement Time:** 10-15 minutes\n**Collaboration Mode:** Small Group\n\n**Learning Objective:** Students will critically assess the implications of data limitations on model training and performance, developing an understanding of real-world AI development challenges.\n\n**Instructor Note:** Encourage students to think about false negatives (the model failing to identify a violation because it wasn't in the training data) and the potential for the model to learn an incomplete set of best practices. This highlights the importance of data quality and completeness.",
    "_anchor_text": "While this evaluation avoids data leakage and allow us to automatically evaluate model performance, it has a limitation: while\\nit is reasonable to assume that the human comments for a given\\ncode-review snapshot are correct, they are not exhaustive. In other\\nwords, it is possible that the code in a given code-review snapshot\\ncould be improved according to multiple best practices, but a human reviewer did not post comments (with URLs) for all of them.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #7: Anatomy of a 'Not Useful' Comment\n**Content Type:** Conceptual/Problem-Solving\n**Cognitive Focus:** Critical analysis, understanding user experience, problem identification\n\n**Scaffold Prompt:**\nBased on the example provided, why is a comment that links to \"several topics or complex topics\" considered \"not useful\" from the perspective of the code author? What makes a code review comment *truly useful* for someone trying to improve their code?\n\n**Strategy Foundation:** Explanation Generation, TIPP&SEE (Identify the Problem)\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Pair\n\n**Learning Objective:** Students will analyze the characteristics of effective and ineffective code review feedback, focusing on clarity, specificity, and actionable advice.\n\n**Instructor Note:** Guide students to consider the cognitive load on the author. A useful comment is precise, points directly to the issue, and ideally offers a clear path to resolution, rather than requiring the author to sift through a broad document.",
    "_anchor_text": "The most interesting  nding from this study was that there were\\nclear patterns of not useful comments. Here are some examples:\\nSeveral topics or complex topic: For example, one URL points\\nto a section that describes multiple guidelines for interacting with\\nthe Python linter, including cases where it often triggers and ways\\nto suppress it. An author may struggle to understand what speci c\\nguideline a posted comment is referring to and how to resolve it.",
    "_type": "comment"
  }
]