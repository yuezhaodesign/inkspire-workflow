[
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": 892,
    "rangeEnd": 1180,
    "fragment": "Modern code review is a process in which an incremental code contribution made by a code author is reviewed by one or more peers\nbefore it is committed to the version control system. An important\nelement of modern code review is verifying that code contributions\nadhere to best practices.",
    "text": "### Scaffold #1: Defining Modern Code Review\n**Content Type:** Conceptual\n**Cognitive Focus:** Conceptual understanding, connecting to prior knowledge\n\n**Scaffold Prompt:** Think about a time you've worked on a group project where someone else looked at your work before it was finalized. How is 'modern code review' similar to or different from that experience? What specific 'best practices' do you think are most important for code?\n\n**Strategy Foundation:** Activation Prompts, Explanation Generation\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Pair\n\n**Learning Objective:** Students will articulate the core components of modern code review and identify relevant best practices, linking new concepts to their existing understanding of collaborative work.\n\n**Instructor Note:** Encourage students to consider both technical and social aspects of code review. Prompt them to think about *why* best practices are important, not just what they are.",
    "_anchor_text": "Modern code review is a process in which an incremental code contribution made by a code author is reviewed by one or more peers\nbefore it is committed to the version control system. An important\nelement of modern code review is verifying that code contributions\nadhere to best practices.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #2: The Limits of Automation\n**Content Type:** Conceptual\n**Cognitive Focus:** Understanding limitations, critical thinking about rule-based systems\n\n**Scaffold Prompt:** Consider a common programming 'best practice' like variable naming conventions. Why might it be difficult for an automated tool to perfectly enforce this rule across all codebases, especially older ones? Can you think of another example where human judgment is indispensable in code review?\n\n**Strategy Foundation:** Analogy Construction, Explanation Generation\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Small Group\n\n**Learning Objective:** Students will recognize the inherent challenges in automating the verification of nuanced coding guidelines and appreciate the role of human judgment and collective knowledge in code quality.\n\n**Instructor Note:** Guide students to differentiate between 'syntactic' rules (easy to automate) and 'semantic' or 'contextual' rules (harder to automate). Discuss how this impacts the design of AI-assisted tools.",
    "_anchor_text": "However, nuanced guidelines or those with exceptions are difficult to automatically verify in their entirety (e.g., naming conventions and justified deviations in legacy code), and some guidelines cannot be captured by precise rules at all (e.g., clarity and specificity of code comments) and rely on human judgement and collective developer knowledge.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #3: Model Input and Output Structure\n**Content Type:** Hybrid\n**Cognitive Focus:** System architecture, input/output mapping\n\n**Scaffold Prompt:** Imagine you're designing this AI model. Draw a simple diagram showing the 'Input' (task prompt + source code) going into a 'Black Box' (the model), and then what comes out as 'Target' (location + URL). Why do you think the task prompt is formatted as a code comment?\n\n**Strategy Foundation:** Visualization Requests, Code-Concept Mapping\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Individual\n\n**Learning Objective:** Students will visualize the data flow for the AI model's best practice analysis and understand the purpose of structuring the task prompt as a code comment.\n\n**Instructor Note:** Emphasize the importance of clearly defined inputs and outputs for any system. Discuss how the 'code comment' format might integrate naturally into developer workflows.",
    "_anchor_text": "For the best practice analysis, the input to the model is a task prompt and source code, and the target is a source code location and a URL for a best practice violation. The task prompt is formatted as a fixed-text code comment, using the programming language’s appropriate commenting style.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #4: Tracing the Example\n**Content Type:** Code\n**Cognitive Focus:** Code tracing, purpose articulation\n\n**Scaffold Prompt:** Look at the provided 'Input' code. If the AI model were to identify a best practice violation, where in the `Add` function do you think it might point, and what kind of 'best practice' might be violated, given the task prompt? Explain your reasoning in plain English, without just restating the code.\n\n**Strategy Foundation:** PRIMM-Investigate, Purpose Articulation\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Pair\n\n**Learning Objective:** Students will practice interpreting code examples in the context of AI analysis, predicting potential violations, and articulating the purpose of the model's output.\n\n**Instructor Note:** Guide students to consider common Go language best practices (e.g., variable naming, comment clarity, error handling, although not explicitly shown here). Focus on the *why* behind the potential violation.",
    "_anchor_text": "Input\n/ / [ ∗ ] T a s k: Check l a n g u a g e b e s t p r a c t i c e s.\n/ / P a c k a g e a d d i t i o n p r o v i d e s Add\npackage a d d i t i o n\n/ / R e t u r n a sum\nfunc Add ( v a l u e 1, v a l u e 2 i n t ) i n t {\nreturn v a l u e 1 + v a l u e 2\n}\nTarget\nINSERT 1 5 3 COMMENT h t t p s:...",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #5: Deconstructing the Pipeline\n**Content Type:** Conceptual\n**Cognitive Focus:** Understanding system components, reasoning about design choices\n\n**Scaffold Prompt:** Even without seeing Figure 2, what do you imagine 'preprocessing' and 'curation' might involve when creating a dataset for training an AI model on code review? Why would 'preprocessing' be significantly more expensive if it handles a much larger amount of data?\n\n**Strategy Foundation:** Visualization Requests, Explanation Generation\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Small Group\n\n**Learning Objective:** Students will infer the general steps involved in dataset creation for AI models and reason about the computational costs associated with processing large datasets.\n\n**Instructor Note:** Encourage students to think about data cleaning, normalization, and feature extraction for 'preprocessing,' and more refined selection or labeling for 'curation.' Discuss the practical implications of data volume on resource allocation.",
    "_anchor_text": "Figure 2 shows the architecture of the model-training pipeline, which consists of three parts. We split dataset creation into two steps (preprocessing and curation) because the first step is significantly more expensive as it operates on a much larger amount of data.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": 17394,
    "rangeEnd": 17642,
    "fragment": "While this evaluation avoids data leakage and allow us to automatically evaluate model performance, it has a limitation: while\nit is reasonable to assume that the human comments for a given\ncode-review snapshot are correct, they are not exhaustive.",
    "text": "### Scaffold #6: Evaluating Evaluation Limitations\n**Content Type:** Problem-Solving\n**Cognitive Focus:** Critical evaluation of research methods, understanding trade-offs\n\n**Scaffold Prompt:** The text states that human comments are 'not exhaustive.' What does this mean for the AI model's evaluation? If the model identifies a best practice violation that humans *didn't* comment on, is the model necessarily wrong? How might this limitation affect our confidence in the model's reported performance?\n\n**Strategy Foundation:** Metacognitive Prompts, Error Prediction\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Pair\n\n**Learning Objective:** Students will critically analyze a stated limitation of the evaluation methodology, understanding its implications for interpreting model performance and the challenges of using human-generated data as ground truth.\n\n**Instructor Note:** Guide students to consider the difference between 'absence of evidence' and 'evidence of absence.' This is a key point in understanding the nuances of AI evaluation where ground truth can be incomplete.",
    "_anchor_text": "While this evaluation avoids data leakage and allow us to automatically evaluate model performance, it has a limitation: while\nit is reasonable to assume that the human comments for a given\ncode-review snapshot are correct, they are not exhaustive.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #7: Interpreting Evaluation Metrics\n**Content Type:** Problem-Solving\n**Cognitive Focus:** Interpreting quantitative data, identifying implications\n\n**Scaffold Prompt:** The AutoCommenter detects violations in 6% of changed files, but 80% of its comments would be on *unmodified* lines. What does this tell you about the practical utility of the tool in a real-world code review setting? What kind of 'noise' might these 80% of comments represent, and why is that problematic?\n\n**Strategy Foundation:** Explanation Generation, Comparison Tasks\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Small Group\n\n**Learning Objective:** Students will interpret quantitative evaluation results to assess the practical implications of an AI tool's performance, particularly regarding the trade-off between detection and relevance.\n\n**Instructor Note:** Discuss the concept of 'actionability' in code review feedback. Comments on unmodified lines, even if technically correct, can distract reviewers and authors, leading to 'alert fatigue' or reduced trust in the tool.",
    "_anchor_text": "An evaluation using per-URL thresholds with greedy decoding on full historical code reviews revealed that AutoCommenter detects violations in 6% of all changed files. However, 80% of comments would have been posted on lines of code not modified by the author.",
    "_type": "comment"
  },
  {
    "positionStartX": 0.0,
    "positionStartY": 1.0,
    "positionEndX": 0.48,
    "positionEndY": 1.67,
    "rangeType": "text",
    "rangePage": 1,
    "rangeStart": -1,
    "rangeEnd": -1,
    "fragment": "",
    "text": "### Scaffold #8: Value vs. Correctness\n**Content Type:** Problem-Solving\n**Cognitive Focus:** Understanding practical implications, balancing correctness with utility\n\n**Scaffold Prompt:** Think about the 'net negative value' concept. Can you imagine a similar situation outside of coding where a technically correct correction might actually be counterproductive or cause more harm than good? What factors contribute to a comment being 'low-value' in a code review, even if it's technically correct?\n\n**Strategy Foundation:** Analogy Construction, Explanation Generation\n**Expected Engagement Time:** 5-10 minutes\n**Collaboration Mode:** Pair\n\n**Learning Objective:** Students will understand the distinction between technical correctness and practical value in feedback, applying this concept to code review and identifying factors that make feedback low-value.\n\n**Instructor Note:** Encourage students to consider the human element: developer time, cognitive load, and the overall goal of code review (improving code quality efficiently). This highlights the socio-technical nature of software development.",
    "_anchor_text": "Correct but low-value comments: A missing period at the end of a sentence in a code comment is often allowed by human reviewers. While technically correct, asking the author to go back to their IDE and fix the issue may provide net negative value.",
    "_type": "comment"
  }
]